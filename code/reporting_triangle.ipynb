{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "innocent-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from epiweeks import Week, Year\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaning-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'https://raw.githubusercontent.com/KITmetricslab/nowcasting-data/main/'\n",
    "\n",
    "MAX_DELAY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atmospheric-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASE = 'Seasonal_Influenza' \n",
    "# DISEASE = 'RSV_Infection'\n",
    "# DISEASE = 'Pneumococcal_Disease'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thermal-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION_CODES = {'Deutschland': 'DE',\n",
    "                  'Schleswig-Holstein': 'DE-SH',\n",
    "                  'Hamburg': 'DE-HH',\n",
    "                  'Niedersachsen': 'DE-NI',\n",
    "                  'Bremen': 'DE-HB',\n",
    "                  'Nordrhein-Westfalen': 'DE-NW',\n",
    "                  'Hessen': 'DE-HE',\n",
    "                  'Rheinland-Pfalz': 'DE-RP',\n",
    "                  'Baden-Württemberg': 'DE-BW',\n",
    "                  'Bayern': 'DE-BY',\n",
    "                  'Saarland': 'DE-SL',\n",
    "                  'Berlin': 'DE-BE',\n",
    "                  'Brandenburg': 'DE-BB',\n",
    "                  'Mecklenburg-Vorpommern': 'DE-MV',\n",
    "                  'Sachsen': 'DE-SN',\n",
    "                  'Sachsen-Anhalt': 'DE-ST',\n",
    "                  'Thüringen': 'DE-TH'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ages_by_group(age_group):\n",
    "    if age_group == '80+':\n",
    "        return {'A80.': '80+'}\n",
    "    limits = age_group.split('-')\n",
    "    keys = [f'A{a:02d}..{a:02d}' for a in range(int(limits[0]), int(limits[1]) + 1)]\n",
    "    return dict.fromkeys(keys, age_group)\n",
    "\n",
    "AGE_GROUPS = ['00+', '00-04', '05-14', '15-34', '35-59', '60-79', '80+']\n",
    "\n",
    "AGE_DICT = dict()\n",
    "for age_group in AGE_GROUPS[1:]:\n",
    "    AGE_DICT.update(ages_by_group(age_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_file(df):\n",
    "    # add iso date (end date of the corresponding week)\n",
    "    df['date'] = df.apply(lambda x: Week(x.year, x.week, system = 'iso').enddate(), axis = 1)\n",
    "    \n",
    "    df = df.rename(columns = {'stratum' : 'location'})\n",
    "    \n",
    "    # fix state names and replace with abbreviations\n",
    "    df.location = df.location.replace({'Ã.': 'ü', '\\.': '-'}, regex = True)\n",
    "    df.location = df.location.replace(LOCATION_CODES)\n",
    "    \n",
    "    # fill in age_group\n",
    "    df['age_group'] = '00+'\n",
    "    \n",
    "    df = df[['date', 'year', 'week', 'location', 'age_group', 'value']]\n",
    "    df = df.sort_values(['location', 'age_group', 'date'], ignore_index = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "green-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age_file(df):\n",
    "    # add iso date (end date of the corresponding iso week)\n",
    "    df['date'] = df.apply(lambda x: Week(x.year, x.week, system = 'iso').enddate(), axis = 1)\n",
    "    \n",
    "    df = df.rename(columns = {'stratum' : 'age_group'})\n",
    "    \n",
    "    # drop entries with unknown age group\n",
    "    df = df[df.age_group != \"Unbekannt\"]\n",
    "    \n",
    "    # summarize age groups (from yearly resolution to specified groups)\n",
    "    df.age_group = df.age_group.replace(AGE_DICT)\n",
    "    df = df.groupby(['date', 'year', 'week', 'age_group'], as_index = False)['value'].sum()\n",
    "    \n",
    "    # compute sum for age group 00+\n",
    "    df_all = df.groupby(['date', 'year', 'week'], as_index = False)['value'].sum()\n",
    "    df_all['age_group'] = '00+'\n",
    "    \n",
    "    df = pd.concat([df, df_all])\n",
    "    \n",
    "    # fill in location\n",
    "    df['location'] = 'DE'\n",
    "    \n",
    "    df = df[['date', 'year', 'week', 'location', 'age_group', 'value']]\n",
    "    df = df.sort_values(['location', 'age_group', 'date'], ignore_index = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "catholic-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(disease, date):\n",
    "    try:\n",
    "        df1 = pd.read_csv(f\"{PATH}/{disease}/{disease}-states-{date}.csv\")\n",
    "        df2 = pd.read_csv(f\"{PATH}/{disease}/{disease}-age-{date}.csv\")\n",
    "\n",
    "        df1 = process_state_file(df1)\n",
    "        df2 = process_age_file(df2)\n",
    "\n",
    "        df = pd.concat([df1, df2])\n",
    "        df = df.sort_values(['location', 'age_group', 'date'], ignore_index = True)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latest-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_iso_dates(df):\n",
    "    '''\n",
    "    Adds iso_week, iso_year and iso_date (end date of the week) to dataframe.\n",
    "    '''\n",
    "    df['iso_week'] = df.date.apply(lambda x: Week.fromdate(x, system = 'iso').week)\n",
    "    df['iso_year'] = df.date.apply(lambda x: Week.fromdate(x, system = 'iso').year)\n",
    "    df['iso_date'] = df.apply(lambda x: Week(x.iso_year, x.iso_week, system = 'iso'), axis = 1)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "comprehensive-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Check if there's a difference for age/state\n",
    "def list_all_files(disease, stratum='state'):\n",
    "    # download all files from repo\n",
    "    url = 'https://api.github.com/repos/KITmetricslab/nowcasting-data/git/trees/main?recursive=1'\n",
    "    r = requests.get(url)\n",
    "    res = r.json()\n",
    "    \n",
    "    # filter relevant files\n",
    "    files = sorted([file['path'] for file in res['tree'] if (file['path'].startswith(disease) and \n",
    "                                                             file['path'].endswith('.csv') and\n",
    "                                                             stratum in file['path'])])\n",
    "    \n",
    "    # create dataframe so we can easily select files by date\n",
    "    df_files = pd.DataFrame({'filename':files})\n",
    "\n",
    "    # extract date from filename\n",
    "    df_files['date'] = df_files.filename.str[-14:-4]\n",
    "    df_files.date = pd.to_datetime(df_files.date)\n",
    "    \n",
    "    df_files = add_iso_dates(df_files)\n",
    "    \n",
    "    # only keep latest file per week\n",
    "    df_files = df_files.sort_values('date').groupby(['iso_year', 'iso_week']).tail(1).reset_index(drop = True)\n",
    "    \n",
    "    return df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "otherwise-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_dates(df_files):\n",
    "    # map iso_date to date of the latest available file of the corresponding week\n",
    "    date_dict = dict(zip(df_files.iso_date, df_files.date))\n",
    "    \n",
    "    max_date = df_files.iso_date.max().enddate()\n",
    "    min_date = df_files.iso_date.min().enddate()\n",
    "    \n",
    "    dates = pd.date_range(min_date, max_date, freq = \"1W\")\n",
    "    dates = [Week.fromdate(d, system = 'iso') for d in dates]\n",
    "    \n",
    "    # remove current week as the data might not be available/final yet\n",
    "    dates.remove(Week.thisweek(system = 'iso'))\n",
    "    \n",
    "    return date_dict, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stretch-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_placeholder(date, \n",
    "                     states = ['DE-BB', 'DE-BE', 'DE-BW', 'DE-BY', 'DE-HB', 'DE-HE',\n",
    "                               'DE-HH', 'DE-MV', 'DE-NI', 'DE-NW', 'DE-RP', 'DE-SH', 'DE-SL',\n",
    "                               'DE-SN', 'DE-ST', 'DE-TH'], \n",
    "                     age_groups = ['00+', '00-04', '05-14', '15-34', '35-59', '60-79', '80+']):\n",
    "    \n",
    "    if DISEASE == 'RSV_Infection':\n",
    "        states = ['DE-SN']\n",
    "    \n",
    "    df_age_groups = pd.DataFrame({'date'     : date.enddate(),\n",
    "                      'year'     : date.year, \n",
    "                      'week'     : date.week,\n",
    "                      'location' : 'DE', \n",
    "                      'age_group': age_groups,\n",
    "                      'value'    : np.nan})\n",
    "\n",
    "    df_states = pd.DataFrame({'date'     : date.enddate(),\n",
    "                      'year'     : date.year, \n",
    "                      'week'     : date.week,\n",
    "                      'location' : states, \n",
    "                      'age_group': '00+',\n",
    "                      'value'    : np.nan})\n",
    "\n",
    "    return pd.concat([df_age_groups, df_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "connected-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_template(dates, \n",
    "                  states = ['DE-BB', 'DE-BE', 'DE-BW', 'DE-BY', 'DE-HB', 'DE-HE',\n",
    "                            'DE-HH', 'DE-MV', 'DE-NI', 'DE-NW', 'DE-RP', 'DE-SH', 'DE-SL',\n",
    "                            'DE-SN', 'DE-ST', 'DE-TH'], \n",
    "                  age_groups = ['00+', '00-04', '05-14', '15-34', '35-59', '60-79', '80+']):\n",
    "    \n",
    "    dfs = []\n",
    "    for d in dates:\n",
    "        df = make_placeholder(d)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, ignore_index = True)\n",
    "    df = df.drop(columns = ['value'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "creative-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_delayed_data(date, data_version):\n",
    "    if data_version in date_dict.keys():\n",
    "        df = load_data(disease = DISEASE, date = date_dict[data_version].date())\n",
    "    else:\n",
    "        df = None\n",
    "\n",
    "    # select relevant rows if df_temp is not None\n",
    "    if df is not None:\n",
    "        df = df[(df.date == date.enddate())]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "specific-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = list_all_files(DISEASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fitting-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>iso_week</th>\n",
       "      <th>iso_year</th>\n",
       "      <th>iso_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSV_Infection/RSV_Infection-states-2021-11-07.csv</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>44</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021W44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RSV_Infection/RSV_Infection-states-2021-11-14.csv</td>\n",
       "      <td>2021-11-14</td>\n",
       "      <td>45</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021W45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RSV_Infection/RSV_Infection-states-2021-11-21.csv</td>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>46</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021W46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RSV_Infection/RSV_Infection-states-2021-11-28.csv</td>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021W47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSV_Infection/RSV_Infection-states-2021-12-03.csv</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>48</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021W48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename       date  iso_week  \\\n",
       "0  RSV_Infection/RSV_Infection-states-2021-11-07.csv 2021-11-07        44   \n",
       "1  RSV_Infection/RSV_Infection-states-2021-11-14.csv 2021-11-14        45   \n",
       "2  RSV_Infection/RSV_Infection-states-2021-11-21.csv 2021-11-21        46   \n",
       "3  RSV_Infection/RSV_Infection-states-2021-11-28.csv 2021-11-28        47   \n",
       "4  RSV_Infection/RSV_Infection-states-2021-12-03.csv 2021-12-03        48   \n",
       "\n",
       "   iso_year iso_date  \n",
       "0      2021  2021W44  \n",
       "1      2021  2021W45  \n",
       "2      2021  2021W46  \n",
       "3      2021  2021W47  \n",
       "4      2021  2021W48  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nutritional-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dict, dates = get_relevant_dates(df_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "boolean-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea43d789059f424b95964d3813d2962d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = make_template(dates)\n",
    "for delay in tqdm(range(0, MAX_DELAY + 1), total = MAX_DELAY + 1):\n",
    "    relevant_dates = [d for d in dates if d <= max(dates) - delay]\n",
    "    df_temp = make_template(relevant_dates)\n",
    "    dfs = []\n",
    "    for date in relevant_dates:\n",
    "        data_version = date + delay \n",
    "        df_delayed = load_delayed_data(date, data_version)\n",
    "        dfs.append(df_delayed)    \n",
    "    df_delayed = pd.concat(dfs)\n",
    "    df_temp = df_temp.merge(df_delayed, how = 'left')\n",
    "\n",
    "    # we flag missing values to fill later on (not all should be filled to preserve reporting triangle shape)\n",
    "    df_temp.value = df_temp.value.fillna('to_fill')  \n",
    "    \n",
    "    df_temp = df_temp.rename(columns = {'value': f'value_{delay}w'})\n",
    "    \n",
    "    df = df.merge(df_temp, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "executed-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use latest file to compute column for remaining correction beyond the specified largest delay\n",
    "df_latest = load_data(DISEASE, dates[-1].enddate())\n",
    "\n",
    "df_latest.value = df_latest.value.fillna('to_fill')\n",
    "df_latest = df_latest.rename(columns = {'value': f'value_>{MAX_DELAY}w'})\n",
    "\n",
    "df = df.merge(df_latest, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "connected-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to keep the triangle shape and avoid filling the corresponding entries\n",
    "df = df.fillna('not_observed')\n",
    "\n",
    "df = df.replace({'to_fill' : np.nan})\n",
    "\n",
    "# if initial report is missing replace with zero\n",
    "df.value_0w = df.value_0w.fillna(0)\n",
    "\n",
    "# we use forward filling to fill missing values in between\n",
    "df = df.fillna(method = \"ffill\", axis = 1)\n",
    "\n",
    "df = df.replace({'not_observed' : np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "played-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute differences\n",
    "df.iloc[:, 6:] = df.iloc[:, 5:].diff(axis=1).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indian-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_cols = [c for c in df.columns if 'value' in c]\n",
    "for col in value_cols:\n",
    "    df[col] = df[col].astype('Int64')\n",
    "\n",
    "df = df[['location', 'age_group', 'year', 'week', 'date'] + value_cols]\n",
    "\n",
    "df = df.sort_values(['location', 'age_group', 'date'], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "suspected-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'../data/truth/truth_{DISEASE.lower()}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
